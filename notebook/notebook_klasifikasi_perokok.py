# -*- coding: utf-8 -*-
"""notebook-klasifikasi-perokok.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qm9l3gAe9a81QFFOm_0CKmkvP8ty_gbd

# Klasifikasi Perokok dan Non-perokok

- Nama : Stephen Helenus Ruswawnto Kaawoan
- Email : stephenhelk@gmail.com
- Linkedin : [Linkedin](https://www.linkedin.com/in/stephenhelenus/)
- Instagram [Instagram](instagram.com/stephenhelenus)

# Import Library
"""

from google.colab import userdata
import os
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import math
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score

"""# Memuat Dataset"""

# Ambil kredensial dari Google Colab Secrets
kaggle_username = userdata.get('kaggle_username')  # Nama pengguna
kaggle_key = userdata.get('kaggle_key')     # Kunci API

# Set variabel lingkungan untuk Kaggle
os.environ['KAGGLE_USERNAME'] = kaggle_username
os.environ['KAGGLE_KEY'] = kaggle_key

!kaggle datasets download -d kukuroo3/body-signal-of-smoking

!unzip body-signal-of-smoking.zip

df = pd.read_csv('smoking.csv')
df = df.sample(n=5000, random_state=42)

"""# Exploratory Data Analysis (EDA)

## Struktur Data
"""

df.head()

df = df.drop(columns=[
    'ID', 'height(cm)', 'waist(cm)', 'eyesight(left)', 'eyesight(right)',
    'hearing(left)', 'hearing(right)', 'fasting blood sugar', 'Cholesterol',
    'triglyceride', 'HDL', 'LDL', 'Urine protein', 'AST', 'ALT', 'oral', 'dental caries'
])

row, col = df.shape
print(f"Jumlah kolom: {col}")
print(f"Jumlah baris: {row}")

df.info()

df.describe()

"""## Cek NULL dan DUPLICATED"""

df.isnull().sum()
df.dropna(inplace=True)

df.duplicated().sum()
df.drop_duplicates(inplace=True)

"""## Menangani Outlier"""

numeric_columns = df.select_dtypes(include=['number']).columns

n_cols = 2  # jumlah kolom subplot
n_rows = math.ceil(len(numeric_columns) / n_cols)  # hitung jumlah baris yang diperlukan

plt.figure(figsize=(n_cols * 6, n_rows * 4))

for i, col in enumerate(numeric_columns, 1):
    plt.subplot(n_rows, n_cols, i)
    sns.boxplot(y=df[col], color="skyblue")
    plt.title(f"Boxplot of {col}")

    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    print(f"{col} column: {len(outliers)} outlier")

plt.tight_layout()
plt.show()

columns_to_check = df.select_dtypes(include=['number']).columns

def remove_outliers(df, columns):
    for col in columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]

    return df

df = remove_outliers(df, columns_to_check)

numeric_columns = df.select_dtypes(include=['number']).columns

n_cols = 3  # jumlah kolom subplot
n_rows = math.ceil(len(numeric_columns) / n_cols)  # hitung jumlah baris yang diperlukan

plt.figure(figsize=(n_cols * 6, n_rows * 4))

for i, col in enumerate(numeric_columns, 1):
    plt.subplot(n_rows, n_cols, i)
    sns.boxplot(y=df[col], color="skyblue")
    plt.title(f"Boxplot of {col}")

    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    print(f"{col} column: {len(outliers)} outlier")

plt.tight_layout()
plt.show()

"""## Visualisasi Data Numerik & Kategorikal"""

numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
n = len(numerical_cols)

total_plots = 2 * n

rows = n

fig, axes = plt.subplots(rows, 2, figsize=(12, 4 * rows))

for i, col in enumerate(numerical_cols):
    sns.histplot(df[col], kde=True, bins=30, ax=axes[i, 0])
    axes[i, 0].set_title(f'Histogram of {col}')

    sns.boxplot(x=df[col], ax=axes[i, 1])
    axes[i, 1].set_title(f'Boxplot of {col}')

plt.tight_layout()
plt.show()

#Visualisasi Data Kategorikal
categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
print("Categorical columns:", categorical_cols)

# Countplot untuk data kategorikal
for col in categorical_cols:
    plt.figure(figsize=(6,4))
    sns.countplot(data=df, x=col, order=df[col].value_counts().index)
    plt.title(f'Countplot of {col}')
    plt.xticks(rotation=45)
    plt.show()

plt.figure(figsize=(10, 6))
df.select_dtypes(include=['number']).hist(figsize=(16, 12), bins=20, edgecolor='black')
plt.suptitle("Histogram Distribusi Variabel Numerik")
plt.show()

plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Heatmap Korelasi Antar Variabel")
plt.show()

"""fasting blood sugar, Cholesterol, triglyceride, Urine protein	Merokok tidak selalu berdampak langsung terhadap parameter-parameter ini, dan bisa memiliki noise tinggi (dipengaruhi pola makan, genetik, dsb)

Systolic & Relaxation (tekanan darah)

GTP (γ-GTP), ALT, AST (indikator fungsi hati → sangat terpengaruh oleh merokok dan alkohol)

Hemoglobin

Serum Creatinine

HDL / LDL (jika tetap dipertahankan → indikator jantung)

Tartar dan Dental Caries (berhubungan dengan kebersihan mulut dan dampak nikotin)

## Encoding Fitur Kategorikal
"""

label_encoder = LabelEncoder()

categorical_columns = ['gender', 'tartar']

for column in categorical_columns:
    df[column] = label_encoder.fit_transform(df[column])

df.head()

"""## Standarisasi Fitur Numerik"""

# Buat instance StandardScaler
scaler = StandardScaler()

X = df.drop(columns=['smoking'])
y = df['smoking']

numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns
X[numeric_columns] = scaler.fit_transform(X[numeric_columns])

plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Heatmap Korelasi Antar Variabel")
plt.show()

"""# Data Splitting"""

# Split data menjadi set pelatihan dan set uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Tampilkan bentuk set pelatihan dan set uji untuk memastikan split
print(f"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}")
print(f"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}")

"""# Pelatihan Model"""

lr = LogisticRegression().fit(X_train, y_train)
svm = SVC().fit(X_train, y_train)

print("Model training selesai.")

# Fungsi untuk mengevaluasi dan mengembalikan hasil sebagai kamus
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    results = {
        'Confusion Matrix': cm,
        'True Positive (TP)': tp,
        'False Positive (FP)': fp,
        'False Negative (FN)': fn,
        'True Negative (TN)': tn,
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred),
        'Recall': recall_score(y_test, y_pred),
        'F1-Score': f1_score(y_test, y_pred)
    }
    return results

# Mengevaluasi setiap model dan mengumpulkan hasilnya
results = {
    'Logistic Regression (LR)': evaluate_model(lr, X_test, y_test),
    'Support Vector Machine (SVM)': evaluate_model(svm, X_test, y_test),
}

# Buat DataFrame untuk meringkas hasil
summary_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])

# Isi DataFrame dengan hasil
rows = []
for model_name, metrics in results.items():
    rows.append({
        'Model': model_name,
        'Accuracy': metrics['Accuracy'],
        'Precision': metrics['Precision'],
        'Recall': metrics['Recall'],
        'F1-Score': metrics['F1-Score']
    })

# Konversi daftar kamus ke DataFrame
summary_df = pd.DataFrame(rows)

# Tampilkan DataFrame
print(summary_df)

# Parameter grid untuk Logistic Regression
param_grid_lr = {
    'C': [0.01, 0.1, 1, 10],       # Regularisasi
    'solver': ['liblinear', 'lbfgs']
}

# Parameter grid untuk SVM
param_grid_svm = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf'],   # Jenis kernel
    'gamma': ['scale', 'auto']     # Parameter kernel RBF
}

# Inisialisasi model dasar
base_lr = LogisticRegression()
base_svm = SVC()

# Lakukan GridSearchCV untuk Logistic Regression
grid_search_lr = GridSearchCV(base_lr, param_grid_lr, cv=5, scoring='f1', n_jobs=-1)
grid_search_lr.fit(X_train, y_train)
best_lr = grid_search_lr.best_estimator_
print("Best Logistic Regression Parameters:", grid_search_lr.best_params_)

# Lakukan GridSearchCV untuk SVM
grid_search_svm = GridSearchCV(base_svm, param_grid_svm, cv=5, scoring='f1', n_jobs=-1)
grid_search_svm.fit(X_train, y_train)
best_svm = grid_search_svm.best_estimator_
print("Best SVM Parameters:", grid_search_svm.best_params_)

# Evaluasi kembali menggunakan model terbaik
tuned_results = {
    'Logistic Regression (Tuned)': evaluate_model(best_lr, X_test, y_test),
    'Support Vector Machine (Tuned)': evaluate_model(best_svm, X_test, y_test),
}

# Gabungkan hasil evaluasi awal dan hasil tuning
for model_name, metrics in tuned_results.items():
    results[model_name] = metrics

# Perbarui summary DataFrame
rows = []
for model_name, metrics in results.items():
    rows.append({
        'Model': model_name,
        'Accuracy': metrics['Accuracy'],
        'Precision': metrics['Precision'],
        'Recall': metrics['Recall'],
        'F1-Score': metrics['F1-Score']
    })

summary_df = pd.DataFrame(rows)
print("\n=== Ringkasan Performa Model ===")
print(summary_df)

"""# Evaluasi"""

# Daftar model terbaik untuk evaluasi akhir
final_models = {
    "Logistic Regression (Tuned)": best_lr,
    "Support Vector Machine (Tuned)": best_svm
}

# Fungsi untuk mencetak classification report dan plot confusion matrix
def evaluate_and_report(model, model_name, X_test, y_test):
    y_pred = model.predict(X_test)

    # Classification Report
    print(f"=== Classification Report: {model_name} ===")
    print(classification_report(y_test, y_pred))

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(4, 3))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f"Confusion Matrix - {model_name}")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.tight_layout()
    plt.show()

# Evaluasi untuk semua model akhir
for name, model in final_models.items():
    evaluate_and_report(model, name, X_test, y_test)

