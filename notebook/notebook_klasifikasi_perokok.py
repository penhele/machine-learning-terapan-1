# -*- coding: utf-8 -*-
"""notebook-klasifikasi-perokok.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qm9l3gAe9a81QFFOm_0CKmkvP8ty_gbd

# Klasifikasi Perokok dan Non-perokok

- Nama : Stephen Helenus Ruswawnto Kaawoan
- Email : stephenhelk@gmail.com
- Linkedin : [Linkedin](https://www.linkedin.com/in/stephenhelenus/)
- Instagram [Instagram](instagram.com/stephenhelenus)

# Import Library
"""

from google.colab import userdata
import os
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import math
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score

"""# Memuat Dataset"""

# Ambil kredensial dari Google Colab Secrets
kaggle_username = userdata.get('kaggle_username')  # Nama pengguna
kaggle_key = userdata.get('kaggle_key')     # Kunci API

# Set variabel lingkungan untuk Kaggle
os.environ['KAGGLE_USERNAME'] = kaggle_username
os.environ['KAGGLE_KEY'] = kaggle_key

!kaggle datasets download -d kukuroo3/body-signal-of-smoking

!unzip body-signal-of-smoking.zip

df = pd.read_csv('smoking.csv')
df = df.sample(n=5000, random_state=42)

"""# Exploratory Data Analysis (EDA)

## Struktur Data

Bagian ini merupakan melihat struktur dan isi dari dataset
"""

df.head()

df = df.drop(columns=[
    'ID', 'height(cm)', 'waist(cm)', 'eyesight(left)', 'eyesight(right)',
    'hearing(left)', 'hearing(right)', 'fasting blood sugar', 'Cholesterol',
    'triglyceride', 'HDL', 'LDL', 'Urine protein', 'AST', 'ALT', 'oral', 'dental caries'
])

row, col = df.shape
print(f"Jumlah kolom: {col}")
print(f"Jumlah baris: {row}")

df.info()

"""Insight: Berdasarkan hasil yang telah didapat, diketahui bahwa jumlah kolom dan baris setelah penghapusan kolom yang tidak perlu adalah sebanyak 10 kolom dan 500 baris. Kemudian pada `df.info()` diketahui bahwa tidak ada baris yang berisi null dan data type yang beragam.

## Cek NULL dan DUPLICATED

Melakukan pengecekan nilai NULL dan baris DUPLICATED
"""

df.isnull().sum()
df.dropna(inplace=True)

df.duplicated().sum()
df.drop_duplicates(inplace=True)

"""Insight: Dari hasil pengecekan NULL dan DUPLICATED, tidak ada baris yang mendapatkannya. Hal ini berarti bagus karena nilai NULL dan baris DUPLICATED dapat mengacaukan modeling data.

## Menangani Outlier

Melihat dan menangani outlier pada kolom bertipe data number
"""

numeric_columns = df.select_dtypes(include=['number']).columns

n_cols = 2  # jumlah kolom subplot
n_rows = math.ceil(len(numeric_columns) / n_cols)  # hitung jumlah baris yang diperlukan

plt.figure(figsize=(n_cols * 6, n_rows * 4))

for i, col in enumerate(numeric_columns, 1):
    plt.subplot(n_rows, n_cols, i)
    sns.boxplot(y=df[col], color="skyblue")
    plt.title(f"Boxplot of {col}")

    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    print(f"{col} column: {len(outliers)} outlier")

plt.tight_layout()
plt.show()

columns_to_check = df.select_dtypes(include=['number']).columns

def remove_outliers(df, columns):
    for col in columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]

    return df

df = remove_outliers(df, columns_to_check)

numeric_columns = df.select_dtypes(include=['number']).columns

n_cols = 3  # jumlah kolom subplot
n_rows = math.ceil(len(numeric_columns) / n_cols)  # hitung jumlah baris yang diperlukan

plt.figure(figsize=(n_cols * 6, n_rows * 4))

for i, col in enumerate(numeric_columns, 1):
    plt.subplot(n_rows, n_cols, i)
    sns.boxplot(y=df[col], color="skyblue")
    plt.title(f"Boxplot of {col}")

    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
    print(f"{col} column: {len(outliers)} outlier")

plt.tight_layout()
plt.show()

"""Insight: Setelah diketahui terdapat outlier, kemudian dihilangkan. Meski masih ada beberapa outlier, tapi tidak terlalu berpengaruh dibandingkan sebelumnya.

## Visualisasi Data Numerik & Kategorikal

Menvisualisasikan data numerik dan data kategorikal
"""

numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
n = len(numerical_cols)

total_plots = 2 * n

rows = n

fig, axes = plt.subplots(rows, 2, figsize=(12, 4 * rows))

for i, col in enumerate(numerical_cols):
    sns.histplot(df[col], kde=True, bins=30, ax=axes[i, 0])
    axes[i, 0].set_title(f'Histogram of {col}')

    sns.boxplot(x=df[col], ax=axes[i, 1])
    axes[i, 1].set_title(f'Boxplot of {col}')

plt.tight_layout()
plt.show()

#Visualisasi Data Kategorikal
categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
print("Categorical columns:", categorical_cols)

# Countplot untuk data kategorikal
for col in categorical_cols:
    plt.figure(figsize=(6,4))
    sns.countplot(data=df, x=col, order=df[col].value_counts().index)
    plt.title(f'Countplot of {col}')
    plt.xticks(rotation=45)
    plt.show()

plt.figure(figsize=(10, 6))
df.select_dtypes(include=['number']).hist(figsize=(16, 12), bins=20, edgecolor='black')
plt.suptitle("Histogram Distribusi Variabel Numerik")
plt.show()

plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Heatmap Korelasi Antar Variabel")
plt.show()

"""Insight:
1. Pada visualisasi data numerik, diperlihatkan jumlah masing-masing kolom dan outliernya. Pada data kategorikal, juga diperlihatkan jumlah data dari masing-masing kolom.
2. Pada korelasi antar variabel, terlihat bahwa tekanan darah sistolik dan diastolik (relaxation) memiliki korelasi positif yang kuat (0.74), menandakan bahwa keduanya saling berhubungan erat secara fisiologis. Variabel hemoglobin menunjukkan korelasi cukup tinggi dengan smoking (0.39), begitu pula GTP (0.31) dan serum creatinine (0.28), yang mengindikasikan bahwa faktor-faktor terkait fungsi darah dan organ tubuh mungkin berhubungan dengan kebiasaan merokok. Berat badan juga berkorelasi sedang dengan hemoglobin (0.52), serum creatinine (0.39), dan GTP (0.39), menunjukkan adanya hubungan antara massa tubuh dan kondisi kesehatan organ. Korelasi antar fitur lainnya terhadap smoking tergolong lemah, sehingga pemodelan prediktif berbasis linear kemungkinan tidak cukup, dan pendekatan algoritma non-linear seperti Random Forest atau XGBoost lebih direkomendasikan. Selain itu, tidak ditemukan indikasi multikolinearitas yang ekstrem antar fitur, sehingga seluruh variabel masih dapat digunakan secara bersamaan dalam proses modeling.

## Encoding Fitur Kategorikal

Melakukan encoding fitur kategorikal
"""

label_encoder = LabelEncoder()

categorical_columns = ['gender', 'tartar']

for column in categorical_columns:
    df[column] = label_encoder.fit_transform(df[column])

df.head()

"""Insight: Dari hasil encoding, pada klom `gender` dan `tartar` telah diubah kedalam numerik. Hal ini digunakan untuk modelin, karena machine learning lebih baik mendeteksi menggunakan angka.

## Standarisasi Fitur Numerik

Melakukan standarisai fitur numerik
"""

# Buat instance StandardScaler
scaler = StandardScaler()

X = df.drop(columns=['smoking'])
y = df['smoking']

numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns
X[numeric_columns] = scaler.fit_transform(X[numeric_columns])

plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Heatmap Korelasi Antar Variabel")
plt.show()

"""Insight: Standarisasi digunakan untuk menyamakan skala fitur (variabel) dalam dataset agar memiliki kontribusi yang setara dalam analisis atau pemodelan. Kemudian untuk melihat korelasinya, di mana akan mendeteksi kolom `gender` dan  `tartar`, bahwa kolom `gender` sangat berkorelasi dengan kolom `age`, `weight`, dan `hemoglobin`.

# Data Splitting

Split data menjadi set pelatihan dan set uji
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}")
print(f"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}")

"""Insight: Dataset telah dibagi dengan proporsi 80:20 menggunakan train_test_split, menghasilkan 3088 data latih dan 773 data uji, masing-masing dengan 9 fitur. Pembagian ini memastikan model dapat belajar dan diuji secara objektif, sementara random_state=42 digunakan agar hasil pembagian konsisten.

# Pelatihan Model
"""

lr = LogisticRegression().fit(X_train, y_train)
svm = SVC().fit(X_train, y_train)

print("Model training selesai.")

# Fungsi untuk mengevaluasi dan mengembalikan hasil sebagai kamus
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    results = {
        'Confusion Matrix': cm,
        'True Positive (TP)': tp,
        'False Positive (FP)': fp,
        'False Negative (FN)': fn,
        'True Negative (TN)': tn,
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred),
        'Recall': recall_score(y_test, y_pred),
        'F1-Score': f1_score(y_test, y_pred)
    }
    return results

# Mengevaluasi setiap model dan mengumpulkan hasilnya
results = {
    'Logistic Regression (LR)': evaluate_model(lr, X_test, y_test),
    'Support Vector Machine (SVM)': evaluate_model(svm, X_test, y_test),
}

# Buat DataFrame untuk meringkas hasil
summary_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])

# Isi DataFrame dengan hasil
rows = []
for model_name, metrics in results.items():
    rows.append({
        'Model': model_name,
        'Accuracy': metrics['Accuracy'],
        'Precision': metrics['Precision'],
        'Recall': metrics['Recall'],
        'F1-Score': metrics['F1-Score']
    })

# Konversi daftar kamus ke DataFrame
summary_df = pd.DataFrame(rows)

# Tampilkan DataFrame
print(summary_df)

# Parameter grid untuk Logistic Regression
param_grid_lr = {
    'C': [0.01, 0.1, 1, 10],       # Regularisasi
    'solver': ['liblinear', 'lbfgs']
}

# Parameter grid untuk SVM
param_grid_svm = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf'],   # Jenis kernel
    'gamma': ['scale', 'auto']     # Parameter kernel RBF
}

# Inisialisasi model dasar
base_lr = LogisticRegression()
base_svm = SVC()

# Lakukan GridSearchCV untuk Logistic Regression
grid_search_lr = GridSearchCV(base_lr, param_grid_lr, cv=5, scoring='f1', n_jobs=-1)
grid_search_lr.fit(X_train, y_train)
best_lr = grid_search_lr.best_estimator_
print("Best Logistic Regression Parameters:", grid_search_lr.best_params_)

# Lakukan GridSearchCV untuk SVM
grid_search_svm = GridSearchCV(base_svm, param_grid_svm, cv=5, scoring='f1', n_jobs=-1)
grid_search_svm.fit(X_train, y_train)
best_svm = grid_search_svm.best_estimator_
print("Best SVM Parameters:", grid_search_svm.best_params_)

# Evaluasi kembali menggunakan model terbaik
tuned_results = {
    'Logistic Regression (Tuned)': evaluate_model(best_lr, X_test, y_test),
    'Support Vector Machine (Tuned)': evaluate_model(best_svm, X_test, y_test),
}

# Gabungkan hasil evaluasi awal dan hasil tuning
for model_name, metrics in tuned_results.items():
    results[model_name] = metrics

# Perbarui summary DataFrame
rows = []
for model_name, metrics in results.items():
    rows.append({
        'Model': model_name,
        'Accuracy': metrics['Accuracy'],
        'Precision': metrics['Precision'],
        'Recall': metrics['Recall'],
        'F1-Score': metrics['F1-Score']
    })

summary_df = pd.DataFrame(rows)
print("=== Ringkasan Performa Model ===")
print(summary_df)

"""Insight: Berdasarkan hasil evaluasi, model Support Vector Machine (SVM) dan Logistic Regression (LR) menunjukkan performa yang cukup baik sebelum dan sesudah tuning. Setelah dilakukan hyperparameter tuning menggunakan GridSearchCV, kedua model mengalami peningkatan kinerja. Logistic Regression yang dituning memperoleh sedikit peningkatan pada akurasi (dari 0.714 ke 0.721) dan F1-Score (dari 0.641 ke 0.654). Sementara itu, SVM yang dituning mencatatkan recall tertinggi (0.816), menunjukkan kemampuannya yang sangat baik dalam mendeteksi kelas positif, meskipun precision-nya sedikit menurun. Secara keseluruhan, SVM yang telah dituning memberikan performa terbaik dari segi F1-Score (0.676), menjadikannya kandidat model yang paling optimal untuk digunakan pada dataset ini.

# Evaluasi

Menampilkan evaluasi terakhir dari hasil yang didapatkan pada model di atas
"""

# Daftar model terbaik untuk evaluasi akhir
final_models = {
    "Logistic Regression (Tuned)": best_lr,
    "Support Vector Machine (Tuned)": best_svm
}

# Fungsi untuk mencetak classification report dan plot confusion matrix
def evaluate_and_report(model, model_name, X_test, y_test):
    y_pred = model.predict(X_test)

    # Classification Report
    print(f"=== Classification Report: {model_name} ===")
    print(classification_report(y_test, y_pred))

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(4, 3))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f"Confusion Matrix - {model_name}")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.tight_layout()
    plt.show()

# Evaluasi untuk semua model akhir
for name, model in final_models.items():
    evaluate_and_report(model, name, X_test, y_test)

"""Insight: Berdasarkan hasil classification report untuk model terbaik yang telah dituning, baik Logistic Regression maupun Support Vector Machine (SVM) mencapai akurasi keseluruhan sebesar 72%. Namun, perbedaan muncul dalam keseimbangan antara precision dan recall. Logistic Regression (Tuned) memiliki precision lebih tinggi untuk kelas negatif (0.83) namun lebih rendah untuk kelas positif (0.59), sedangkan SVM (Tuned) menunjukkan recall yang sangat tinggi pada kelas positif (0.82), meskipun precision-nya lebih rendah (0.58). Artinya, SVM lebih baik dalam mendeteksi kasus positif, namun dengan konsekuensi prediksi positif palsu yang lebih banyak. Dalam konteks di mana deteksi kelas positif lebih penting, seperti deteksi penyakit atau risiko, SVM (Tuned) bisa menjadi pilihan yang lebih unggul karena recall-nya yang tinggi."""